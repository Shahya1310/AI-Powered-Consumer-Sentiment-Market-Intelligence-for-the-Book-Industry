# ğŸ“ Project Organization â€” FINAL âœ…

## âœ¨ Cleaned and Organized!

All files are now in their proper locations with **data, scripts, and documentation clearly separated**.
This structure follows standard ML project practices and is mentorâ€‘review ready.

---

## ğŸ“‚ Clean Directory Structure

```
ai-consumer-sentiment-data-collection/
â”‚
â”œâ”€â”€ ğŸ“– DOCUMENTATION (Root Level)
â”‚   â”œâ”€â”€ README.md                    # Main project overview
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md        # Technical pipeline reference
â”‚   â”œâ”€â”€ RESULTS_GUIDE.md            # How to view outputs
â”‚   â””â”€â”€ FILE_ORGANIZATION.md        # Folder structure guide (this file)
â”‚
â”œâ”€â”€ âš™ï¸ CONFIGURATION (Root Level)
â”‚   â”œâ”€â”€ requirements.txt            # All dependencies
â”‚   â”œâ”€â”€ .env                        # API keys (GROQ_API_KEY)
â”‚   â””â”€â”€ .env.example                # Environment template
â”‚
â”œâ”€â”€ ğŸ“Š SENTIMENT ANALYSIS
â”‚   â””â”€â”€ sentiment_analysis/
â”‚       â”œâ”€â”€ sentiment_analysis.py           # LLM sentiment pipeline
â”‚       â”œâ”€â”€ sentiment_analysis_batch.py     # Batch Groq processing
â”‚       â”œâ”€â”€ show_results_summary.py         # Statistics summary
â”‚       â”œâ”€â”€ test_groq_connection.py         # API connectivity test
â”‚       â””â”€â”€ README.md                       # Usage documentation
â”‚
â”œâ”€â”€ ğŸ“Š DATA
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ raw/                   # Original scraped data
â”‚       â”‚   â”œâ”€â”€ ecommerce_books.csv
â”‚       â”‚   â”œâ”€â”€ news_articles.csv
â”‚       â”‚   â””â”€â”€ youtube_book_comments.csv
â”‚       â”‚
â”‚       â””â”€â”€ processed/             # Cleaned & analyzed datasets
â”‚           â”œâ”€â”€ cleaned_text.csv
â”‚           â”œâ”€â”€ sentiment_analysis_results.csv â­
â”‚           â””â”€â”€ topic_results.csv
â”‚
â”œâ”€â”€ ğŸ›  PIPELINE MODULES
â”‚   â”œâ”€â”€ data_collection/           # Scraping & API scripts
â”‚   â”œâ”€â”€ data_preprocessing/        # Cleaning & normalization
â”‚   â””â”€â”€ topic_modeling/            # LLM topic extraction scripts
â”‚
â””â”€â”€ ğŸ“ .git/
```

---

## âœ… What Was Cleaned

### ğŸ—‘ï¸ Removed Duplicates

* All sentiment scripts consolidated into `sentiment_analysis/`
* Old rootâ€‘level scripts removed
* Visualization experiments removed
* Topic outputs moved into `data/processed/`

### ğŸ“ Root Directory Now

```
ai-consumer-sentiment-data-collection/
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ FILE_ORGANIZATION.md
â”œâ”€â”€ PROJECT_STRUCTURE.md
â”œâ”€â”€ README.md
â”œâ”€â”€ RESULTS_GUIDE.md
â””â”€â”€ requirements.txt
```

Only essential configuration and documentation remain at root.

---

## ğŸ“ Where Everything Is

| Item                     | Location                                        |
| ------------------------ | ----------------------------------------------- |
| Sentiment results        | `data/processed/sentiment_analysis_results.csv` |
| Topic extraction results | `data/processed/topic_results.csv`              |
| Sentiment scripts        | `sentiment_analysis/`                           |
| Data collection scripts  | `data_collection/`                              |
| Cleaning scripts         | `data_preprocessing/`                           |
| Topic modeling scripts   | `topic_modeling/`                               |
| API keys                 | `.env` (root)                                   |

---

## ğŸš€ Quick Start

### â–¶ View Summary

```bash
cd sentiment_analysis
python show_results_summary.py
```

### â–¶ Run Sentiment Analysis

```bash
cd sentiment_analysis
python sentiment_analysis_batch.py
```

### â–¶ Test Groq API

```bash
cd sentiment_analysis
python test_groq_connection.py
```

---

## ğŸ“Š Results Snapshot

```
Total Records: 344
â”œâ”€ Positive: ~43%
â”œâ”€ Negative: ~28%
â”œâ”€ Neutral:  ~29%
â””â”€ Avg Confidence: ~0.74
```

Topic modeling results stored separately in `topic_results.csv`.

---

## ğŸ“š Documentation Map

| File                         | Purpose              |
| ---------------------------- | -------------------- |
| README.md                    | Project overview     |
| RESULTS_GUIDE.md             | How to view outputs  |
| PROJECT_STRUCTURE.md         | Pipeline explanation |
| FILE_ORGANIZATION.md         | Folder map           |
| sentiment_analysis/README.md | Script usage         |

---

## âœ… Status

âœ” Clean folder structure
âœ” LLM-based sentiment analysis implemented
âœ” Batch processing enabled
âœ” Topic extraction via LLM
âœ” Validation and insights completed
âœ” Mentorâ€‘ready repository

---

If new datasets or domains are added later, they should be placed under:

```
data/raw/
data/processed/
```

and new analysis modules under:

```
<new_module_name>/
```

This ensures the pipeline remains scalable and easy to extend.
